{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building text corpus using BeautifulSoup\n",
    "\n",
    "The goal of this code is to perform web scraping for text extraction from a list of company websites. The objective is to collect relevant textual information from these websites for the purpose of classifying companies by industry using Natural Language Processing (NLP).\n",
    "\n",
    "The process involves sending HTTP requests to the specified websites, retrieving the HTML content, parsing it to extract text, and filtering out non-English text. The extracted text is then stored in a pandas DataFrame along with the corresponding website URLs. \n",
    "\n",
    "Afterwards, we will test if this DataFrame can serve as a foundational dataset for subsequent analysis, text classification, and machine learning tasks related to the categorization of companies based on the content of their websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # HTTP library for making web requests\n",
    "from bs4 import BeautifulSoup #HTML parsing library for web scraping\n",
    "import langid #Language identification library for text\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>year founded</th>\n",
       "      <th>industry</th>\n",
       "      <th>size range</th>\n",
       "      <th>locality</th>\n",
       "      <th>country</th>\n",
       "      <th>linkedin url</th>\n",
       "      <th>current employee estimate</th>\n",
       "      <th>total employee estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5872184</td>\n",
       "      <td>ibm</td>\n",
       "      <td>ibm.com</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>information technology and services</td>\n",
       "      <td>10001+</td>\n",
       "      <td>new york, new york, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/ibm</td>\n",
       "      <td>274047</td>\n",
       "      <td>716906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2309813</td>\n",
       "      <td>us army</td>\n",
       "      <td>goarmy.com</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>military</td>\n",
       "      <td>10001+</td>\n",
       "      <td>alexandria, virginia, united states</td>\n",
       "      <td>united states</td>\n",
       "      <td>linkedin.com/company/us-army</td>\n",
       "      <td>162163</td>\n",
       "      <td>445958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0     name      domain  year founded  \\\n",
       "0             0     5872184      ibm     ibm.com        1911.0   \n",
       "1             3     2309813  us army  goarmy.com        1800.0   \n",
       "\n",
       "                              industry size range  \\\n",
       "0  information technology and services     10001+   \n",
       "1                             military     10001+   \n",
       "\n",
       "                              locality        country  \\\n",
       "0    new york, new york, united states  united states   \n",
       "1  alexandria, virginia, united states  united states   \n",
       "\n",
       "                   linkedin url  current employee estimate  \\\n",
       "0      linkedin.com/company/ibm                     274047   \n",
       "1  linkedin.com/company/us-army                     162163   \n",
       "\n",
       "   total employee estimate  \n",
       "0                   716906  \n",
       "1                   445958  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"1.2_web_scrap_source.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = ['https://ibm.com', 'https://goarmy.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract English text from a website\n",
    "def extract_text(url):\n",
    "    try:\n",
    "        # Send a GET request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad requests\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract text from the HTML (modify this based on your website structure)\n",
    "        text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
    "\n",
    "        # Check if the text is in English\n",
    "        if langid.classify(text)[0] == 'en':\n",
    "            return text\n",
    "        else:\n",
    "            print(f\"Text from {url} is not in English.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ibm.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://goarmy.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Website\n",
       "0     https://ibm.com\n",
       "1  https://goarmy.com"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty DataFrame\n",
    "df2 = pd.DataFrame({'Website': df['domain'].apply(lambda x: f'https://{x}')})\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from https://ibm.com is not in English.\n"
     ]
    }
   ],
   "source": [
    "# Apply the extract_text function to each website and create a new column 'Text'\n",
    "df2['Text'] = df2['Website'].apply(extract_text)\n",
    "\n",
    "# Save the DataFrame to a CSV file or perform further analysis\n",
    "df2.to_csv('testextract.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secondtry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
